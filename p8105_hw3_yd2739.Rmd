---
title: "p8105_hw3_yd2739"
author: "Yuxuan Du"
date: "2023-10-05"
output: github_document
---
```{r}
library(tidyverse)
library(p8105.datasets)
```
## Problem 1

```{r}
#load dataset and make the variable name tidy
data("instacart")
tidy_instacart = instacart |>
  janitor::clean_names()
```
the size of the dataset is `r nrow(tidy_instacart)` x `r ncol(tidy_instacart)`

The variables in the data are `r colnames(tidy_instacart)`

#### calculate aisle number and order aisle by their frequency and find item ordered most
```{r}

aisle_number = 
  tidy_instacart|>
  pull(
    aisle_id
  )|>
  unique()|>
  length()

aisle_ordered = tidy_instacart|>
  group_by(aisle)|>
  summarize(n_obs = n())|>
  arrange(desc(n_obs))

head(aisle_ordered)|>
  knitr::kable()
```

There are `r aisle_number` unique aisle in the dataset, and the most consumed aisle is `r aisle_ordered[1, 1]`. 

#### select aisle appeared more than 10000 times and make plot about the frequency and their name
```{r}

aisle_plot = aisle_ordered|>
  subset(
    n_obs >= 10000
  )|>
  arrange(desc(n_obs))|>
  ggplot(aes(x = reorder(aisle, +n_obs), y = n_obs)) + 
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)) +
  coord_flip()
        
aisle_plot
```

#### Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits"
```{r}

popular_baking_ingredients_df = tidy_instacart|>
  subset(
    aisle == "baking ingredients"
  )|>
  group_by(product_name)|>
  summarize(n_obs = n())|>
  arrange(desc(n_obs)) |>
  head(3)|>
  mutate(
    category = "baking ingredients"
  )
popular_baking_ingredients_df|>
  knitr::kable()
```

```{r}
popular_dog_food_care_df = tidy_instacart|>
  subset(
    aisle == "dog food care"
  )|>
  group_by(product_name)|>
  summarize(n_obs = n())|>
  arrange(desc(n_obs)) |>
  head(3)|>
  mutate(
    category = "dog food care"
  )
popular_dog_food_care_df|>
  knitr::kable()
```

```{r}
popular_packaged_vegetables_fruits_df = tidy_instacart|>
  subset(
    aisle == "packaged vegetables fruits"
  )|>
  group_by(product_name)|>
  summarize(n_obs = n())|>
  arrange(desc(n_obs)) |>
  head(3)|>
  mutate(
    category = "packaged vegetables fruits"
  )
popular_packaged_vegetables_fruits_df|>
  knitr::kable()
```

```{r}
three_items_merged = bind_rows(
  popular_baking_ingredients_df, 
  popular_dog_food_care_df, 
  popular_packaged_vegetables_fruits_df)|>
  arrange(desc(n_obs))|>
  knitr::kable()
  
three_items_merged
```

#### Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. 
```{r}
apples_coffee_df = tidy_instacart|>
  subset(
    product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream"
  )|>
  group_by(order_dow, product_name)|>
  summarize(
    mean_hour = mean(order_hour_of_day, na.rm = TRUE)
  )|>
  mutate(
    order_dow = case_match(
      order_dow, 
      0 ~ "Sunday", 
      1 ~ "Monday", 
      2 ~ "Tuesday", 
      3 ~ "Wednesday", 
      4 ~ "Thursday", 
      5 ~ "Friday", 
      6 ~ "Saturday"
    )
  )|>
  knitr::kable(digits = 1)

apples_coffee_df
```


## Problem 2

#### data cleaning: load data, tidy col names, select a subset of overall health and factorize response column
```{r}

data("brfss_smart2010")
BRFSS_cleaned = brfss_smart2010 |>
  janitor::clean_names()|>
  subset(
    topic == "Overall Health"
  )|>
  subset(
    response == "Excellent" | response == "Very good" | response == "Good"|response == "Fair"|response == "Poor"
  )|>
  mutate(
    response = factor(response, level=c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

#### find states were observed at 7 or more locations in 2002 and 2010
```{r}
seven_or_more_2002 = BRFSS_cleaned|>
  subset(year == 2002)|>
  group_by(locationabbr)|>
  summarize(n_loc = n_distinct(locationdesc))|>
  subset(n_loc >= 7)|>
  arrange(desc(n_loc))
seven_or_more_2002|>
  knitr::kable()
  
```

In 2002, `r seven_or_more_2002[[1]]` are states observed at 7 or more locations. 
```{r}
seven_or_more_2010 = BRFSS_cleaned|>
  subset(year == 2010)|>
  group_by(locationabbr)|>
  summarize(n_loc = n_distinct(locationdesc))|>
  subset(n_loc >= 7)|>
  arrange(desc(n_loc))
seven_or_more_2010|>
  knitr::kable()
```
In 2010, `r seven_or_more_2010[[1]]` are states observed at 7 or more locations. 

#### average value over time with states for the Excellent response
```{r}
excellent_df = BRFSS_cleaned|>
  subset(
    response == "Excellent"
  )|>
  group_by(year, locationabbr)|>
  summarize(mean_data_value = mean(data_value))

excellent_plot = excellent_df|>
  ggplot(aes(x = year, y = mean_data_value))+
  geom_line(aes(color = locationabbr))
excellent_plot
```

It looks hard for interpretation. But there is a state that always has low data value for exellent response. 

#### Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses among locations in NY State
```{r}
NY_distribution_df = BRFSS_cleaned|>
  subset(
    locationabbr == "NY"
  )|>
  subset(
    year == 2006 | year == 2010
  )

NY_distribution_plot = NY_distribution_df|>
  ggplot(aes(x = locationdesc, y = data_value, fill = response)) + 
  geom_col(position = 'stack', width = 0.6)+
  facet_grid(. ~ year)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)) +
  coord_flip()

NY_distribution_plot
```

```{r}
NY_distribution_heatmap = NY_distribution_df|>
  ggplot(aes(x = locationdesc, y = response, fill = data_value)) + 
  geom_tile()+
  facet_grid(. ~ year)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
NY_distribution_heatmap
```

```{r}
NY_distribution_boxplot = NY_distribution_df|>
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot()+
  facet_grid(. ~ year)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))
NY_distribution_boxplot
```

We could see that the median data_value of very good increases from 2006 to 2010. Also, according to the distribution plot, we could observe that there are three more region included in 2010 compare with 2006. As regions changed, it might be not appropriate to use box plot to show the difference in data value. 


## Problem 3
```{r}
#import data and data cleaning
demo_df = 
  read_csv("DATA/nhanes_covar.csv", skip = 4)|>
  janitor::clean_names()|>
  drop_na()|>
  subset(
    age >= 21
  )|>
  mutate(
    sex = recode(sex, "1" = "male", "2" = "female"),
    education = recode(education, "1" = "Less than high school", 
                   "2" = "High school equivalent", 
                   "3" = "More than high school"), 
    sex = factor(sex), 
    education = factor(education)
  )

acc_df = 
  read_csv("DATA/nhanes_accel.csv")|>
  janitor::clean_names()

merged_acc_info_df= left_join(demo_df, acc_df, by = join_by(seqn))

head(merged_acc_info_df)|>
  knitr::kable()

```

```{r}
sex_vs_edu_df  = merged_acc_info_df|>
  group_by(sex, education)|>
  summarize(counts = n())|>
  pivot_wider(names_from = sex, values_from = counts)
  
sex_vs_edu_df|>knitr::kable()
```

```{r}
sex_vs_edu_age_df  = merged_acc_info_df|>
  group_by(sex, education)|>
  summarize(mean_age = mean(age, na.rm = TRUE))

sex_vs_edu_age_plot = merged_acc_info_df|>
  ggplot(aes(x = age, color = sex))+
  geom_density()+
  facet_grid(. ~ education)+
  labs(title = "distribution of different gender across age in different education level", 
       x = "Age in years",
       y = "density ")
sex_vs_edu_age_plot
```

From the plot, we could see the trend that for people who have more than high school degree, more of them are younger people. For people who have less than high school degree, more of them are older people. 

```{r}
acc_info_agg_df = merged_acc_info_df|>
  mutate(
    aggregate_move = rowSums(select(merged_acc_info_df, starts_with("min")))
  )

agg_age_plot = acc_info_agg_df|>
  ggplot(aes(x = age, y = aggregate_move, color = sex))+
  geom_point(alpha = .5)+
  geom_smooth()+
  facet_grid(. ~ education)+
  labs(title = "Overall 24-Hour Activity categorized by Education and Gender", 
       x = "Age in years",
       y = "Overall activity value")
agg_age_plot
```
We could observe that as age exceed 60, all movement starts to decrease regardless of age or education level. In high school group and more than high school group, females shows higher movement compare to male, while less than high school group, male's movement exceed female's movement after exceeding 40 years old. Also, the average movement line for high education level people is smoother. 
```{r}
grouped_24hr_avg_df = merged_acc_info_df|>
  group_by(education, sex)|>
  summarise(across(starts_with("min"), ~ mean(.), .names = "mean_{.col}"))|>
  pivot_longer(cols = starts_with("mean_"), names_to = "time", values_to = "mean")|>
  mutate(
    time = substring(time, 9), 
    time= as.numeric(time)
  )
grouped_24hr_avg_plot = grouped_24hr_avg_df|>
  ggplot(aes(x = time, y = mean, color = sex))+
  geom_line()+
  facet_grid(. ~ education)+
  labs(title = "Average 24-Hour Activity by minutes categorized by Education and Gender", 
       x = "Time in minutes",
       y = "Mean activity value")
grouped_24hr_avg_plot
```

We could observe from the graph that for people have more than high school degree, average movement for female is higher than average movement for male.A All people shows low movement from 0 to 250min, this is probably they are sleeping. 